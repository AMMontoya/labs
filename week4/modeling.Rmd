# Modeling

"All models are wrong, but some are useful" -George E. P. Box

When we see a p-value in the literature it means a probability distribution of some sort was used to quatify the null hypothesis. Many times deciding which probability distribution to use a relatively straight forward. For example, in the tea tasting example. Many p-values in the scientific literature are based on sample averages, or least squares estimates from a linear model, and make use of the CLT to approximate the null distribution of their statistic as normal.

The CLT is backed by theoretical results that guarantee that the approximation is accurate. However, we cannot always use this approximation, for example when our sample size is too small. In a previous module we described how the sample average can be approximated with t-distribution when the population data is approximately normal. Note that there is no theoretical backing for this assumption. We are now *modeling*. In the case of height, we know from experience that this turns out to be a very good model. 

```{r}
datadir="http://www.biostat.jhsph.edu/bstcourse/bio751/data"
dat=read.csv(file.path(datadir,"USheights_subsample.csv"))
men=dat$Height[dat$Gender==1]
qqnorm(men)
qqline(men)
```

But this doesn not imply that every dataset we collect will follow a normal distribtion. Example are: coin tosses, the numner of people who win the lottery, and US incomes.The normal is not the only parametric distribution that is available from modeling. Here we show we describe some useful parametric distribution and their use in genomics. For many more please consult these books [CITE books]

## The Binomial distribution

A distribution that one should be familiar is the binomial distribution. It described the probability of the total number of observed heads $S=k$ heads when tossing $N$ heads as
$$
\mbox{Pr}(S=k) = {N \choose k}p^k (1-p)^{N-k}
$$

with $p$ the probability of observing a head in one coin toss. Note that $S/N$ is the average of independent random variables and thus the CLT tells us that $S$ is approximately normal. This distribution is used by some of the variant callers and genotypers based on NGS to decide if the data is consistent 

## The Poissin distribution

The number of people that win the lottery follows a binomial distribution (we assume each person buys one ticket). The number of "tosses" $N$ is the number of people that buy tickets and very large. However, the number of people that win the lottery oscilates between 0 and 3. So why does CLT not hold? One can explain this mathematically, but the intuition is that with most the average so close to and also constrained to be larger than 0, it is impossible for the distribution to be normal. Here is a quick simulation

```{r}
p=10^-7 ##1 in 10,000,0000 chances of winning
N=5*10^6 ##5,000,000 tickets bought
winners=rbinom(1000,N,p) ##1000 is the number of different lotto draws
tab=table(winners)
plot(tab)
prop.table(tab)
```

For cases like this, where $N$ is very large but $p$ is small enough to make $N \times p$ (call it $\lambda$) a number between 0 and 10, then then $S$ can be shown to follow a Poisson a distribution which has a simple parametric form:
$$
\mbox{Pr}(S=k)=\frac{\lambda^k \exp{-\lambda}{k!}
$$

The Poisson distribution is commonly used in RNAseq analyses. Note that because we are sampling thousands moleculues and for some genes represent are a very small proportion of the totality of molecules, the Poisson distribution seems appropriate. 

Homework
1- Do you expect a Poisson distribution with $\lambda=100$ to be approximately nomral? Why or why not? 


So how does this help us? One way is that it informs us of the statistical properties of important summaries. For example, say we only have one sample from each of a case and control RNAseq experiment and we want to report the genes with larges fold-chages. Note that under the null, that there are no differences, the statistical variability of this quantity depends on the total abundance of the gene. We can show this mathematically but here is a quick simulation to demonstrate the point:
```{r}
N=10000##number of genes
lambdas=2^seq(1,16,len=N) ##these are the true abundances of genes
y=rpois(N,lambdas)##note that the null hypothesis is true for all genes
x=rpois(N,lambdas) 
ind=which(y>0 & x>0)##make sure no 0s due to ratio and log
plot(log2(lambdas[ind]),log2(y/x)[ind])
```
Note that for lower values of lambda there is much more variability and that if we were to report anything with a fold change of 2 or more the number of false positives would be quite high for low.



## NGS experiments and the Poisson distribution

```{r}
library(parathyroidSE)
data(parathyroidGenesSE)
```

This library contains SummarizedExperiment data, which will be discussed in a later lab. The important thing to know is that the SummarizedExperiment has a matrix of data, similar to the ExpressionSet, where each row is a genomic feature, and each column is a sample. For this dataset, the value in single cell in the matrix is count of reads which aligned to a given gene for a given sample.

```{r}
se <- parathyroidGenesSE
as.data.frame(colData(se))
```

```{r}
readsPerSamplePerMill <- round(colSums(assay(se))/1e6, 1)
cbind(experiment=as.data.frame(colData(se))[,"experiment"], rpm=readsPerSamplePerMill)
```

```{r}
x <- assay(se)[,23]
y <- assay(se)[,24]
plot(x,y,log="xy")
abline(0,1,col="red")
```

```{r}
sf <- c(1, sum(y)/sum(x))
z <- cbind(x/sf[1], y/sf[2])
rm <- rowMeans(z)
rv <- (y - rm*sf[2])^2
plot(rm, rv, log="xy", col=rgb(0,0,0,.2))
abline(0,1,col="red")
```





